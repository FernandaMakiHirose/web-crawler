# Desenvolvendo um Web Crawler
- Web crawler é uma ferramenta usada para encontrar, ler e indexar páginas de um site. É como um robô que captura informações de cada um dos links que encontra pela frente, cadastra e compreende o que é mais relevante. (palavras - chaves)
- Muito utilizado em Levantamento de Informações em um Processo de Pentest

## Requisitos
- Python
- Pycharm ou Terminal

## Licença
Distribuido sob a licença MIT License. Veja `LICENSE` para mais informações

## Executar o projeto
No path `\web-crawler` (Substitua o `nomedoarquivo` pelo nome do arquivo que você quer executar):
>python nomedoarquivo.py

## Bibliotecas
- BeautifulSoup - é uma biblioteca de extração de dados de arquivos HTML e XML
- requests
- operator - exporta um conjunto de funções eficientes correspondentes aos operadores intrínsecos do Python como: + - * / not and
- collections - nos ajuda a preencher e manipular eficientemente as estruturas de dados como tuplas, dicionários e listas


